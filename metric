import re

def normalize_query(query):
    # Add your normalization logic here
    # This example handles 'WHERE' conditions with 'AND', 'OR', 'BETWEEN', and '=' operators
    
    # Extract conditions from the query
    conditions_match = re.search(r'WHERE (.+)$', query)
    
    if conditions_match:
        conditions = conditions_match.group(1)
        
        # Split conditions based on 'AND', 'OR'
        conditions_list = re.split(r'\bAND\b|\bOR\b', conditions)
        
        # Normalize and sort conditions
        normalized_conditions = []
        for condition in conditions_list:
            if 'BETWEEN' in condition:
                # Normalize 'BETWEEN' conditions by sorting the range values numerically
                values = re.findall(r'\d+', condition)
                normalized_condition = 'BETWEEN ' + ' AND '.join(map(str, sorted(map(int, values))))
            else:
                # For other conditions, normalize by sorting
                normalized_condition = ' '.join(sorted(re.findall(r'\S+', condition)))

            normalized_conditions.append(normalized_condition)
        
        # Reconstruct the normalized query
        normalized_query = re.sub(r'WHERE (.+)$', 'WHERE ' + ' AND '.join(normalized_conditions), query)
        return normalized_query
    else:
        # If there's no WHERE clause, return the original query
        return query

def compare_queries(true_query, predicted_query):
    # Normalize the true and predicted queries
    normalized_true_query = normalize_query(true_query)
    normalized_predicted_query = normalize_query(predicted_query)

    # Check for equality, ignoring the order of values in the 'BETWEEN' clause
    return sorted(normalized_true_query.split()) == sorted(normalized_predicted_query.split())

def calculate_metrics(predicted_queries, true_queries):
    # Initialize variables for true positives, false positives, and false negatives
    tp = fp = fn = 0

    # Iterate through the predicted and true queries
    for predicted_query in predicted_queries:
        # Check if there is a true query that matches the predicted query
        match_found = any(compare_queries(predicted_query, true_query) for true_query in true_queries)

        if match_found:
            tp += 1
        else:
            fp += 1

    # Calculate false negatives by subtracting true positives from the total true queries
    fn = len(true_queries) - tp

    # Calculate precision, recall, and F1 score
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return precision, recall, f1_score

# Example usage:
predicted_queries = [
    "SELECT * FROM table1 WHERE column1 = 'value1' AND column2 = 'value2'",
    "SELECT * FROM table1 WHERE column2 = 'value2' AND column1 = 'value1'",
    "SELECT * FROM table1 WHERE column3 BETWEEN 10 AND 20"
]
true_queries = [
    "SELECT * FROM table1 WHERE column1 = 'value1' AND column2 = 'value2'",
    "SELECT * FROM table1 WHERE column2 = 'value2' AND column1 = 'value1'",
    "SELECT * FROM table1 WHERE column3 BETWEEN 20 AND 10"
]

precision, recall, f1_score = calculate_metrics(predicted_queries, true_queries)

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)

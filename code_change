from transformers import T5Tokenizer, T5ForConditionalGeneration

# Load pre-trained model and tokenizer
model_name = "t5-small"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)

# Function to generate new questions
def generate_questions(question):
    input_text = f"generate questions: {question}"
    inputs = tokenizer(input_text, return_tensors="pt", max_length=512, truncation=True)
    outputs = model.generate(**inputs, max_length=100, num_return_sequences=4, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)
    generated_questions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]
    return generated_questions

# Iterate through each row, generate new questions, and append to the DataFrame
for index, row in df.iterrows():
    original_question = row['Question']
    generated_questions = generate_questions(original_question)
    
    for i, generated_question in enumerate(generated_questions):
        df = df.append({'Question': generated_question, 'Output': row['Output']}, ignore_index=True)

# Save the augmented DataFrame to a new CSV file
df.to_csv('augmented_data.csv', index=False)

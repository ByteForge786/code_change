import sqlparse

def parse_query(query):
    # Use sqlparse to parse the SQL query and create a tree structure
    parsed_query = sqlparse.parse(query)
    return parsed_query[0].tokens

def compare_trees(tree1, tree2):
    # Compare two tree structures
    if len(tree1) != len(tree2):
        return False

    for token1, token2 in zip(tree1, tree2):
        if token1.ttype != token2.ttype or token1.normalized != token2.normalized:
            return False

        # Recursive comparison for nested structures
        if token1.is_group() and token2.is_group():
            if not compare_trees(token1.tokens, token2.tokens):
                return False

    return True

def calculate_metrics(predicted_queries, true_queries):
    # Ensure both lists have the same length
    assert len(predicted_queries) == len(true_queries), "Input lists must have the same length."

    # Initialize variables for true positives, false positives, and false negatives
    tp = fp = fn = 0

    # Iterate through the predicted and true queries
    for predicted_query, true_query in zip(predicted_queries, true_queries):
        # Parse queries into tree structures
        tree_predicted = parse_query(predicted_query)
        tree_true = parse_query(true_query)

        # Check if the parsed queries are equivalent
        if compare_trees(tree_predicted, tree_true):
            tp += 1
        else:
            fp += 1  # Parsed queries are not equivalent, so it's a false positive
            fn += 1  # True query was not parsed as predicted, so it's a false negative

    # Calculate precision, recall, and F1 score
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return precision, recall, f1_score

# Example usage:
predicted_queries = [
    "SELECT * FROM table1 WHERE column1 = 'value1' AND column2 = 'value2'",
    "SELECT * FROM table1 WHERE column2 = 'value2' AND column1 = 'value1'",
    "SELECT * FROM table1 WHERE column3 BETWEEN 10 AND 20"
]
true_queries = [
    "SELECT * FROM table1 WHERE column1 = 'value1' AND column2 = 'value2'",
    "SELECT * FROM table1 WHERE column2 = 'value2' AND column1 = 'value1'",
    "SELECT * FROM table1 WHERE column3 BETWEEN 20 AND 10"
]

precision, recall, f1_score = calculate_metrics(predicted_queries, true_queries)

print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)
